\subsection*{Abstract}\label{abstract}
\addcontentsline{toc}{subsection}{Abstract}

Echo chambers seem to cause radicalization—and radicalization is risky.
Radicalization undermines institutions by reducing their diversity, 
which in turn impairs their adaptability.  Social psychologists and others study
echo chambers experimentally using \emph{group polarization} experiments.
Researchers induce \emph{group polarization} by first asking experiment
participants their opinions on some topic, then grouping them together if
they agree in spirit, but not degree. The participants then discuss the topic
in their groups. Their opinions are then re-measured. Group polarization is
when the average group opinion increases. But there’s a fatal problem:
participants report opinions on ordinal scales, but this has never been
accounted for statistically. This can cause apparent group polarization in
observations even if the average latent opinion—the one in people’s
heads—doesn’t change, due to ceiling effects. Here we prove that across ten
journal articles spanning five decades that 54 of 57 reported polarization effects are plausibly false due to this artifact, and thus cannot be counted as replications. Our method can be used to evaluate any experimental design that measures latent change with ordinal scales. Given how destructive radicalization can be, we must get this right.


\section{Introduction}\label{introduction}

If an extremist’s opinion falls and it is measured with a Likert scale, will
it make a noise? The answer is often no~\cite{Liddell2018,Turner2020}. This
means a group’s opinions can appear to radicalize over time even when no real
shift occurs. The problem matters because Likert and other ordinal scales are
ubiquitous in research on opinion change and radicalization across the social
and cognitive sciences~\cite{Liddell2018}. One influential framework in this
area is group polarization—the idea that discussion among like-minded people
pushes opinions toward extremes, producing ``echo chambers.'' Cass Sunstein, a
Harvard Law professor and former White House administrator, has written
extensively on the topic~\cite{Sunstein2019}, claiming that group
polarization is a scientific law—a regular, quantitative relationship that
will always be observed when certain assumptions are
met~\cite{Cartwright1999}. Yet Roger Brown himself noted in Social Psychology
that group polarization ``does not occur with every group'' and that ``the
effect is not large.'' Given the influence of this theory and the hundreds of
claimed ``replications,'' it is essential to ask whether many of these findings
may instead be measurement artifacts—spurious effects created when the
``neutral'' point of the measurement scale fails to align with the group’s own
center of opinion.

The group polarization hypothesis is that discussion within a group of
likeminded people causes the group's average opinion to increase, or
\emph{polarize}~\cite{Brown1986,Brown2000}.
Group polarization experiments therefore attempt to
polarize groups as follows: first, participants report their opinion on
some topic or prompt chosen by the experimenters in advance. Second, 
participants are put into likeminded groups to
discuss the topic. Following discussion, participants again report their
opinions on the topic. Group polarization is defined as an increase in
the average opinion following discussion. If the group polarized, and we 
assume that people in the group found consensus—meaning their opinions agreed
more after the discussion than before—then initially moderate opinions must have
increased more than more extreme ones.

We are sad to report that 95\% of experimental reports of group polarization
across sixty published experimental conditions cannot be counted as
replications. We explain here how evidence of group polarization is undermined
by a basic measurement flaw that obscures opinion change among extremists.
This opens the possibility that what seems to be group polarization could just
be \emph{mere agreement}, with no change in mean opinion, if only increases in
opinion were measured but not decreases.  To evaluate whether the empirical
record reflects genuine opinion change or merely measurement artifacts, I
simulated published experiments under conditions of mere agreement. Each
simulation reproduced the core elements of published designs—pre-discussion
survey, group interaction, post-discussion survey—while holding the latent
mean opinion constant. Because the original datasets are lost and published
results rarely provide enough information to reconstruct them, we cannot know
whether any reported effect reflects a real shift or a measurement artifact.
When distinct latent processes can generate indistinguishable results, the
effect is non-identifiable—and no claim of replication can stand.

A relatively simple step could fix the problem: re-center the post-discussion
scale on each group’s own pre-discussion mean, aligning measurement with the
group’s frame rather than an arbitrary external ``neutral.'' This adjustment
restores the basic condition for inference: measuring change within a
consistent frame of reference. 

But even if this measurement problem is fixed,
it is one of several severe problems in this kind of social science: Unstable
opinions, unmodeled input variance, and incommensurate experimental designs
all uniquely undermine any cumulative insight group polarization might
claim—problems known about and ignored for decades~\cite{Cartwright1973}. No
degree of scientific lawfulness can be established without evidence gathered
from rigorously modeled, commensurate experiments~\cite{Cartwright1999}.


\subsection{Group polarization research}

Group polarization research began in the 1960s, which grew rapidly with
funding from the National Institutes of Mental Health (NIMH), and widespread interest
in what was then a surprising new science of radicalization.
Dorian Cartwright (1973) reviewed the first NIMH grants and at the time said,
`` ''.
