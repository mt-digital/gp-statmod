\subsection*{Abstract}\label{abstract}
\addcontentsline{toc}{subsection}{Abstract}

Echo chambers seem to cause radicalization—and radicalization is risky.
Radicalization undermines institutions by reducing their diversity, 
which in turn impairs their adaptability.  Social psychologists and others study
echo chambers experimentally using \emph{group polarization} experiments.
Researchers induce \emph{group polarization} by first asking experiment
participants their opinions on some topic, then grouping them together if
they agree in spirit, but not degree. The participants then discuss the topic
in their groups. Their opinions are then re-measured. Group polarization is
when the average group opinion increases. But there’s a fatal problem:
participants report opinions on ordinal scales, but this has never been
accounted for statistically. This can cause apparent group polarization in
observations even if the average latent opinion—the one in people’s
heads—doesn’t change, due to ceiling effects. Here we prove that across ten
journal articles spanning five decades that 54 of 57 reported polarization effects are plausibly false due to this artifact, and thus cannot be counted as replications. Our method can be used to evaluate any experimental design that measures latent change with ordinal scales. Given how destructive radicalization can be, we must get this right.


\section{Introduction}\label{introduction}

If an extremist’s opinion falls and it is measured with a Likert scale, will
it make a noise? The answer is often no~\cite{Liddell2018,Turner2020}. This
means a group’s opinions can appear to radicalize over time even when no real
shift occurs. The problem matters because Likert and other ordinal scales are
ubiquitous in research on opinion change and radicalization across the social
and cognitive sciences~\cite{Liddell2018}. One influential framework in this
area is group polarization—the idea that discussion among like-minded people
pushes opinions toward extremes, producing ``echo chambers.'' Cass Sunstein, a
Harvard Law professor and former White House administrator, has written
extensively on the topic~\cite{Sunstein2019}, claiming that group
polarization is a scientific law—a regular, quantitative relationship that
will always be observed when certain assumptions are
met~\cite{Cartwright1999}. Yet Roger Brown himself noted in Social Psychology
that group polarization ``does not occur with every group'' and that ``the
effect is not large.'' Given the influence of this theory and the hundreds of
claimed ``replications,'' it is essential to ask whether many of these findings
may instead be measurement artifacts—spurious effects created when the
``neutral'' point of the measurement scale fails to align with the group’s own
center of opinion.

The group polarization hypothesis is that discussion within a group of
likeminded people causes the group's average opinion to increase, or
\emph{polarize}~\cite{Brown1986,Brown2000}.
Group polarization experiments therefore attempt to
polarize groups as follows: first, participants report their opinion on
some topic or prompt chosen by the experimenters in advance. Second, 
participants are put into likeminded groups to
discuss the topic. Following discussion, participants again report their
opinions on the topic. Group polarization is defined as an increase in
the average opinion following discussion. If the group polarized, and we 
assume that people in the group found consensus—meaning their opinions agreed
more after the discussion than before—then initially moderate opinions must have
increased more than more extreme ones.

We are sad to report that 95\% of experimental reports of group polarization
across sixty published experimental conditions cannot be counted as
replications. We explain here how evidence of group polarization is undermined
by a basic measurement flaw that obscures opinion change among extremists.
This opens the possibility that what seems to be group polarization could just
be \emph{mere agreement}, with no change in mean opinion, if only increases in
opinion were measured but not decreases.  To evaluate whether the empirical
record reflects genuine opinion change or merely measurement artifacts, I
simulated published experiments under conditions of mere agreement. Each
simulation reproduced the core elements of published designs—pre-discussion
survey, group interaction, post-discussion survey—while holding the latent
mean opinion constant. Because the original datasets are lost and published
results rarely provide enough information to reconstruct them, we cannot know
whether any reported effect reflects a real shift or a measurement artifact.
When distinct latent processes can generate indistinguishable results, the
effect is non-identifiable—and no claim of replication can stand.

A relatively simple step could fix the problem: re-center the post-discussion
scale on each group’s own pre-discussion mean, aligning measurement with the
group’s frame rather than an arbitrary external ``neutral.'' This adjustment
restores the basic condition for inference: measuring change within a
consistent frame of reference. 

But even if this measurement problem were fixed,
there are several problems in this kind of social science: Unstable
opinions, unmodeled input variance, and incommensurate experimental designs
all uniquely undermine any cumulative insight group polarization might
claim—problems known about and ignored for decades~\cite{Cartwright1973}. No
degree of scientific lawfulness can be established without evidence gathered
from rigorously modeled, commensurate experiments~\cite{Cartwright1999}.


\subsection{Group polarization research}

Group polarization research began in the 1960s, which grew rapidly with
focused government funding coupled with widespread
interest in what was then a surprising new science of
radicalization~\cite{Cartwright1971}. Dorian Cartwright (1973) reviewed the
first decade of group polarization research and found problems: he lamented
the ``disturbing fact'' that group polarization research has produced no
cumulative theoretical undersatnding of the effects of discussion on
group opinions~\cite{Cartwright1973}. Cartwright was somewhat dismayed, but
optimistically hoped that group polarizaiton research would eventually
produce ``an enduring\ldots more comprehensive paradigm'' \cite[p.
230]{Cartwright1973}.

Cartwright (1973) suggested that a ``vigorous search for alternative
formulations'' could help group polarization become more useful. More
researchers developed specific theories of group
polarization, with two becoming particularly influential: social comparisons
and persuasive arguments. The social comparisons hypothesis says group
polarization occurs because humans want to fit in, and so generally like to . Group polarization occurs, then, when a
group is composed mostly of extremists, with a sufficient number of people
with a weak opinion \cite{Myers1970; Myers1975}. Its main
“competitor” from the 1970s was the persuasive arguments theory, which
basically claimed that rhetoric was the strongest driver of group
polarization, not social comparisons \cite{Burnstein1973,Burnstein1975}.

Other notable hypotheses include the
self-categorization and social decisions scheme hypotheses.
Self-categorization augmented the social comparisons hypothesis with a
consideration of idiosyncratic beliefs people hold that are the result of
their own personal lived experience \cite{Abrams1990,Hogg1990}.
The social decisions hypothesis posits that contextual factors like
social network structure could be at least as important as the distribution
of opinions and . Noah Friedkin, a sociologist, notably published
the study with the least potential measurement artifacts for a rigorous study on group polarization, adopting the social
decisions scheme hypothesis, predicting that social connectivity within a
group could amplify group polarization \cite{Friedkin1999}.


\subsection{Measurement procedure}

In most group polarization experiments, opinions are measured on an
ordinal scale: Burnstein and Vinokur (1975) for example used a ten-point
scale from 1 to 10 representing “the lowest odds of success acceptable” to
try a certain behavior, where 1 means 10\%—Moscovici and Zavalloni (1969) gave participants a seven-point scale, from “strongly disagree” (-3) to “strongly agree” (+3) to report their opinions. In these and every other survey-based group polarization study I know, the reported opinions on the ordinal scale—with discrete numbered bins—were treated as if they were continuous-valued, or in other words as if they were the internal mental opinion value itself, whatever that might be neurobiologically. 
Liddell and Kruschke (2018) showed that in the general case this setup can
lead to false positives because ordinal scales cannot track changes in
extreme opinions beyond the ceiling of the measurement scale—this approach is
ubiquitous in social psychology and survey research, not at all limited to
group polarization.


\subsection{Study Corpus}

We selected ten journal articles with sixty total experimental conditions
across the ten. 

\begin{table}[ht]
\caption{\textbf{Journal articles in our corpus.}}
\centering
\begin{tabular}{clcc}
\toprule
Authors (Year) & Title & Journal & Category \\
\midrule
  Moscovici \& Zavalloni (1969) & The Group as a Polarizer of Attitudes &
    Journal of Personality and Social Psychology & Politics \\
    Schkade, Sunstein, \& Hastie & When Deliberation Produces Extremism & Critical Review
                                 & Politics \\
Burnstein \& Vinokur (1973) & Testing Two Classes of Theories About Group Induced Shifts
In Individual Choice & Journal of Experimental Social Psychology & Persuasive Arguments \\

Burnstein \& Vinokur (1975) & What a person thinks upon learning he has chosen differently from others: Nice evidence for the persuasive-arguments explanation of choice shifts & Journal of Experimental Social Psychology & Persuasive Arguments \\
\bottomrule
\end{tabular}
\label{table:mr}
\end{table}


